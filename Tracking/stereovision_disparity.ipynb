{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2.aruco as aruco\n",
    "import pandas as pd\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Compute undistorted frames\n",
    "\"\"\"\n",
    "def undistortRectify(frameR, frameL, leftMapX, leftMapY, rightMapX, rightMapY):\n",
    "    undistortedL= cv2.remap(frameL, leftMapX, leftMapY, cv2.INTER_LANCZOS4, cv2.BORDER_CONSTANT, 0)\n",
    "    undistortedR= cv2.remap(frameR, rightMapX, rightMapY, cv2.INTER_LANCZOS4, cv2.BORDER_CONSTANT, 0)\n",
    "    return undistortedR, undistortedL\n",
    "\"\"\"\n",
    "Compute camera calibration matrices, distortion coefficients, rotation and translation matrices\n",
    "\"\"\"\n",
    "def loadCoefficients():\n",
    "    dir=os.getcwd()\n",
    "    file_path = os.path.join(dir, \"../Calibration\", \"calibrationCoefficients.yaml\")\n",
    "    cv_file = cv2.FileStorage(file_path, cv2.FILE_STORAGE_READ)\n",
    "    camera_matrixL = cv_file.getNode(\"KL\").mat()\n",
    "    dist_matrixL = cv_file.getNode(\"DL\").mat()\n",
    "    camera_matrixR = cv_file.getNode(\"KR\").mat()\n",
    "    dist_matrixR = cv_file.getNode(\"DR\").mat()\n",
    "    rot = cv_file.getNode(\"rot\").mat()\n",
    "    trans = cv_file.getNode(\"trans\").mat()\n",
    "    leftMapX = cv_file.getNode(\"sLX\").mat()\n",
    "    leftMapY = cv_file.getNode(\"sLY\").mat()\n",
    "    rightMapX = cv_file.getNode(\"sRX\").mat()\n",
    "    rightMapY = cv_file.getNode(\"sRY\").mat()\n",
    "    Q = cv_file.getNode(\"Q\").mat()\n",
    "    cv_file.release()\n",
    "    return [camera_matrixL, dist_matrixL, camera_matrixR, dist_matrixR, rot, trans, leftMapX, leftMapY, rightMapX, rightMapY, Q]\n",
    "\n",
    "\n",
    "def find_depth(right_point, left_point, frame_right, frame_left, baseline, f):\n",
    "    _, width_right, _ = frame_right.shape\n",
    "    height_left, width_left, _ = frame_left.shape\n",
    "    frame_left = cv2.cvtColor(frame_left, cv2.COLOR_BGR2GRAY)\n",
    "    frame_right = cv2.cvtColor(frame_right, cv2.COLOR_BGR2GRAY)\n",
    "    Ox = int(width_left/2)\n",
    "    Oy = int(height_left/2)\n",
    "    ## Find focal length in pixels:\n",
    "    if width_right == width_left:\n",
    "         f_pixel = .14\n",
    "    else:\n",
    "         print('Left and right camera frames do not have the same pixel width')\n",
    "    vl = left_point[1]\n",
    "    ul = left_point[0]\n",
    "    vr = right_point[1]\n",
    "    ur = right_point[0]\n",
    "    # CALCULATE THE DISPARITY:\n",
    "    ########## Stereo Rectification #################################################\n",
    "    grayL = frame_left\n",
    "    grayR = frame_right\n",
    "    # Create stereo map\n",
    "    stereoSGBM = cv2.StereoSGBM.create()\n",
    "    stereoSGBM.setMinDisparity(70) #64\n",
    "    stereoSGBM.setNumDisparities(32) #postive and divisible by 16 #32\n",
    "    stereoSGBM.setBlockSize(13) # has to be odd and in range from [5,21] #11\n",
    "    stereoSGBM.setP1(8 * 3 * stereoSGBM.getBlockSize() ** 2) \n",
    "    stereoSGBM.setP2(32 * 3 * stereoSGBM.getBlockSize() ** 2)\n",
    "    stereoSGBM.setUniquenessRatio(10) #10\n",
    "    stereoSGBM.setSpeckleWindowSize(50) #50\n",
    "    stereoSGBM.setSpeckleRange(16) #16\n",
    "# was frame_left_cv and frame_right_cv\n",
    "    disparitySGBM = stereoSGBM.compute(frame_left, frame_right)\n",
    "    # disparity = frame_left-frame_right      # No complex calculations (lightweight)\n",
    "    disparity_img = disparitySGBM\n",
    "    x_disp=int(ur)\n",
    "    y_disp=int(vr)\n",
    "    disparity = disparitySGBM[x_disp,y_disp]\n",
    "    # CALCULATE POSITION: \n",
    "    zDepth = (baseline*f_pixel)/disparity             #Depth in [cm]\n",
    "    yDepth = (baseline*f_pixel*(vl - Oy))/(f_pixel*disparity)\n",
    "    xDepth = (baseline*(ul - Ox))/disparity\n",
    "    return xDepth, yDepth, zDepth, disparity_img, x_disp, y_disp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.5) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\imgwarp.cpp:1703: error: (-215:Assertion failed) !_map1.empty() in function 'cv::remap'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Apply rectification maps\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m frame_right \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe_right\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrightMapX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrightMapY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mINTER_LINEAR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m frame_left \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mremap(frame_left, leftMapX, leftMapY, cv2\u001b[38;5;241m.\u001b[39mINTER_LINEAR)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;124;03mUncomment for HSL/HSV - Comment for RGB\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.5) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\imgwarp.cpp:1703: error: (-215:Assertion failed) !_map1.empty() in function 'cv::remap'\n"
     ]
    }
   ],
   "source": [
    "video_number = 1\n",
    "dir = os.getcwd()\n",
    "video_pathl = dir + \"/Videos/\" + f\"output_camera_nov9_left{video_number}_cropped.mp4\" \n",
    "video_pathr = dir + \"/Videos/\" + f\"output_camera_nov9_right{video_number}_cropped.mp4\" \n",
    "capl = cv2.VideoCapture(video_pathl)\n",
    "capr = cv2.VideoCapture(video_pathr)\n",
    "B = 12.25               #Distance between the cameras [cm]\n",
    "f = 3.67              #Camera lense's focal length [mm]\n",
    "mtxL, distL, mtxR, distR, rot, trans, leftMapX, leftMapY, rightMapX, rightMapY, Q = loadCoefficients()\n",
    "\n",
    "\n",
    "data = {'Marker': [], 'X': [], 'Y': [], 'Z': [], 'Time': []}\n",
    "df = pd.DataFrame(data)\n",
    "frame_count = 0\n",
    "\n",
    "# height_left, width_left = frame_left.shape[:2] (480, 640) \n",
    "Ox = 320\n",
    "Oy = 240\n",
    "\n",
    "while True:\n",
    "    success_right, frame_right = capr.read()\n",
    "    success_left, frame_left = capl.read()\n",
    "\n",
    "    #check if either frame is None\n",
    "    if frame_right is None or frame_left is None:\n",
    "        break\n",
    "\n",
    "    # Apply rectification maps\n",
    "    frame_right = cv2.remap(frame_right, rightMapX, rightMapY, cv2.INTER_LINEAR)\n",
    "    frame_left = cv2.remap(frame_left, leftMapX, leftMapY, cv2.INTER_LINEAR)\n",
    "\n",
    "    \"\"\"\n",
    "    Uncomment for HSL/HSV - Comment for RGB\n",
    "    \"\"\"\n",
    "    # Show the frames\n",
    "    # cv2.imshow(\"frame right\", frame_right) \n",
    "    # cv2.imshow(\"frame left\", frame_left)\n",
    "    # succes_right, frame_right = capr.read()\n",
    "    # succes_left, frame_left = capl.read()\n",
    "    # define range of white color in HSV\n",
    "    # change it according to your need !\n",
    "    # lower_white = np.array([0,0,140])\n",
    "    # upper_white = np.array([255,255,255])\n",
    "\n",
    "    # hsv_right = cv2.cvtColor(frame_right, cv2.COLOR_BGR2RGB)\n",
    "    # hsv_left = cv2.cvtColor(frame_left, cv2.COLOR_BGR2RGB)\n",
    "    # # Threshold the HSV image to get only white colors\n",
    "    # mask_right = cv2.inRange(hsv_right, lower_white, upper_white)\n",
    "    # frame_right = cv2.bitwise_and(frame_right,frame_right, mask= mask_right)\n",
    "    # mask_left = cv2.inRange(hsv_left, lower_white, upper_white)\n",
    "    # frame_left = cv2.bitwise_and(frame_left,frame_left, mask= mask_left)\n",
    "\n",
    "################## CALIBRATION #########################################################\n",
    "\n",
    "    frame_right, frame_left = undistortRectify(frame_right, frame_left, leftMapX, leftMapY, rightMapX, rightMapY)\n",
    "\n",
    "########################################################################################\n",
    "\n",
    "    matrix_coefficients = mtxL\n",
    "    distortion_coefficients = distL\n",
    "\n",
    "    # operations on the frame come here\n",
    "    frame_count += 1\n",
    "    \n",
    "    # Grayscale for HSV\n",
    "    # gray_r = frame_right[:,:,1]\n",
    "    # gray_l = frame_left[:,:,1]\n",
    "\n",
    "    # Show the frames\n",
    "    cv2.imshow(\"frame right\", frame_right) \n",
    "    cv2.imshow(\"frame left\", frame_left)\n",
    "\n",
    "    \"\"\"\n",
    "    Uncomment for HSL/HSV - Comment for RGB\n",
    "    \"\"\"\n",
    "    # bgr_r = cv2.cvtColor(frame_right, cv2.COLOR_HSV2BGR)\n",
    "    # bgr_l = cv2.cvtColor(frame_left, cv2.COLOR_HSV2BGR)\n",
    "    # gray_r = cv2.cvtColor(bgr_r, cv2.COLOR_BGR2GRAY)  # Change grayscale\n",
    "    # gray_l = cv2.cvtColor(bgr_l, cv2.COLOR_BGR2GRAY)  # Change grayscale\n",
    "\n",
    "    \"\"\"\n",
    "    Uncomment for RGB - Comment for HSL/HSV\n",
    "    \"\"\"\n",
    "    gray_r = cv2.cvtColor(frame_right, cv2.COLOR_BGR2GRAY)  # Change grayscale\n",
    "    gray_l = cv2.cvtColor(frame_left, cv2.COLOR_BGR2GRAY)  # Change grayscale\n",
    "\n",
    "    aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_4X4_100)\n",
    "    parameters = cv2.aruco.DetectorParameters()  # Marker detection parameters\n",
    "\n",
    "    # lists of ids and the corners beloning to each id\n",
    "    corners_r, ids_r, rejected_img_points_r = aruco.detectMarkers(gray_r, aruco_dict,\n",
    "                                                            parameters=parameters)\n",
    "                                                            #cameraMatrix=matrix_coefficients,\n",
    "                                                            #distCoeff=distortion_coefficients)\n",
    "                                                            #output coordinates of the 4 corners and the ID of the marker \n",
    "    corners_l, ids_l, rejected_img_points_l = aruco.detectMarkers(gray_l, aruco_dict,\n",
    "                                                            parameters=parameters)\n",
    "                                                            #cameraMatrix=matrix_coefficients,\n",
    "                                                            #distCoeff=distortion_coefficients)\n",
    "                                                            #output coordinates of the 4 corners and the ID of the marker \n",
    "\n",
    "     # operations on the frame come here\n",
    "    # frame_count += 1\n",
    "    # print(\"Frame count\", frame_count)\n",
    "    # If cannot catch any frame, break\n",
    "    if not success_right or not success_left:                    \n",
    "        break\n",
    "\n",
    "    else:\n",
    "       \n",
    "        start = time.time()\n",
    "        \n",
    "        # Convert the BGR image to RGB\n",
    "        frame_right = cv2.cvtColor(frame_right, cv2.COLOR_BGR2RGB)\n",
    "        frame_left = cv2.cvtColor(frame_left, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        \n",
    "        # Convert the RGB image to BGR\n",
    "        frame_right = cv2.cvtColor(frame_right, cv2.COLOR_RGB2BGR)\n",
    "        frame_left = cv2.cvtColor(frame_left, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "\n",
    "        ################## CALCULATING DEPTH #########################################################\n",
    "\n",
    "        center_right = 0\n",
    "        center_left = 0\n",
    "\n",
    "  \n",
    "        if (np.all(ids_r is not None) & np.all(ids_l is not None)).any():\n",
    "        # if np.all(ids_r is not None) and np.all(ids_l is not None):  # If there are markers found by detector\n",
    "            elapsed_time = time.time() - start_time\n",
    "            zipped_r = zip(ids_r, corners_r)\n",
    "            zipped_l = zip(ids_l, corners_l)\n",
    "            \n",
    "            ids_r, corners_r = zip(*(sorted(zipped_r)))\n",
    "            ids_l, corners_l = zip(*(sorted(zipped_l)))\n",
    "            # right is 2\n",
    "            # left is 1\n",
    "            #print('right', + len(ids_r))\n",
    "            #print('left', + len(ids_l))\n",
    "            \n",
    "            axis_r = np.float32([[-0.01, -0.01, 0], [-0.01, 0.01, 0], [0.01, -0.01, 0], [0.01, 0.01, 0]]).reshape(-1, 3)\n",
    "            axis_l = np.float32([[-0.01, -0.01, 0], [-0.01, 0.01, 0], [0.01, -0.01, 0], [0.01, 0.01, 0]]).reshape(-1, 3)\n",
    "            # print('left_len', + len(ids_l))\n",
    "            # print(corners_l)\n",
    "            for i in range(0, len(ids_l)):  # Iterate in markers\n",
    "\n",
    "                if len(ids_l) != len(ids_r):\n",
    "                    continue\n",
    "                else:\n",
    "                    # Estimate pose of each marker and return the values rvec and tvec---different from camera coefficients\n",
    "                    rvec_r, tvec_r, markerPoints_r = aruco.estimatePoseSingleMarkers(corners_r[i], 0.04, matrix_coefficients, distortion_coefficients)\n",
    "                    rvec_l, tvec_l, markerPoints_l = aruco.estimatePoseSingleMarkers(corners_l[i], 0.04, matrix_coefficients, distortion_coefficients)\n",
    "                    #40mm = 0.04m\n",
    "                    #pull out the roation of the marker and the tvec is the center of the four corners\n",
    "            \n",
    "                    x_r = int(np.mean(corners_r[i][0][:,0]))\n",
    "                    x_l = int(np.mean(corners_l[i][0][:,0]))\n",
    "                    y_r = int(np.mean(corners_r[i][0][:,1]))\n",
    "                    y_l = int(np.mean(corners_l[i][0][:,1]))\n",
    "\n",
    "                    #x_r = (corners_r[i-1][0][0][0] + corners_r[i-1][0][1][0] + corners_r[i-1][0][2][0] + corners_r[i-1][0][3][0]) / 4\n",
    "                    #x_l = (corners_l[i-1][0][0][0] + corners_l[i-1][0][1][0] + corners_l[i-1][0][2][0] + corners_l[i-1][0][3][0]) / 4\n",
    "                    #y_r = (corners_r[i-1][0][0][1] + corners_r[i-1][0][1][1] + corners_r[i-1][0][2][1] + corners_r[i-1][0][3][1]) / 4\n",
    "                    #y_l = (corners_l[i-1][0][0][1] + corners_l[i-1][0][1][1] + corners_l[i-1][0][2][1] + corners_l[i-1][0][3][1]) / 4\n",
    "                    center_point_right = np.array([x_r, y_r])\n",
    "                    center_point_left = np.array([x_l, y_l])\n",
    "                    aruco.drawDetectedMarkers(frame_right, corners_r)  # Draw A square around the markers\n",
    "                    aruco.drawDetectedMarkers(frame_left, corners_l)  # Draw A square around the markers\n",
    "            \n",
    "                    #cv2.aruco.drawAxis(frame_right, matrix_coefficients, distortion_coefficients, rvec_r, tvec_r, 0.03)\n",
    "                    #cv2.aruco.drawAxis(frame_left, matrix_coefficients, distortion_coefficients, rvec_l, tvec_l, 0.03)\n",
    "\n",
    "\n",
    "                    # If no marker can be caught in one camera show text \"TRACKING LOST\"\n",
    "                    if not np.all(ids_r is not None) or not np.all(ids_l is not None):\n",
    "                        cv2.putText(frame_right, \"TRACKING LOST\", (75,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255),2)\n",
    "                        cv2.putText(frame_left, \"TRACKING LOST\", (75,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255),2)\n",
    "\n",
    "                    else:\n",
    "                        # Function to calculate depth of object. Outputs vector of all depths in case of several balls.\n",
    "                        # All formulas used to find depth is in video presentaion\n",
    "                        x3d, y3d, depth, disparity_img, x_disp, y_disp = find_depth(center_point_right, center_point_left, frame_right, frame_left, B, f)\n",
    "                        #  disparity_img, x_disp, y_disp\n",
    "                        disparity_img = cv2.normalize(disparity_img, None, 0, 1.0, cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "                        cv2.imshow(\"disp\",disparity_img)\n",
    "                        disp_img = cv2.circle(disparity_img, (x_disp, y_disp), 20, (255, 0, 0), 10)\n",
    "                        cv2.imshow(\"disp\",disp_img)\n",
    "                        cv2.putText(frame_left, \"3D: (\" + str(round(y3d,1)) + ', ' + str(round(x3d,1)) + ', ' + str(round(depth,1)) + ')', (50,50), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0,255,0),3)\n",
    "                            ##########################################​\n",
    "\n",
    "                        #cv2.putText(frame_left, \"3D: (\" + str(round(y3d,1)) + ', ' + str(round(x3d,1)) + ', ' + str(round(depth,1)) + ')', (50,50), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0,255,0),3)\n",
    "                        #cv2.putText(frame_left, \"Distance: \" + str(round(depth,1)), (50,50), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0,255,0),3)\n",
    "                        # Multiply computer value with 205.8 to get real-life depth in [cm]. The factor was found manually.\n",
    "                        print(\"Depth: \", str(round(depth,1)))\n",
    "\n",
    "                        df2 = pd.DataFrame([[ids_r[i][0], x3d, y3d, depth, elapsed_time]], columns=['Marker', 'X', 'Y', 'Z','Time'])\n",
    "                        df = pd.concat([df, df2])\n",
    "\n",
    "        #def save_coefficients(df):\n",
    "        #    cv_file = cv2.FileStorage(r\"C:\\Users\\capam\\Documents\\ComputerVision-master\\ComputerVision-master\\stereoVisionCalibration\\Coefficients.yaml\", cv2.FILE_STORAGE_WRITE)\n",
    "        #    cv_file.write(\"three_coords\", df)\n",
    "        #    cv_file.release()\n",
    "        #save_coefficients(df)\n",
    "        \n",
    "        #def save_coefficients(x3d, y3d, depth):\n",
    "        #    cv_file = cv2.FileStorage(r\"C:\\Users\\capam\\Documents\\ComputerVision-master\\ComputerVision-master\\stereoVisionCalibration\\Coefficients.yaml\", cv2.FILE_STORAGE_WRITE)\n",
    "        #    cv_file.write(\"x_coord\", x3d)\n",
    "        #    cv_file.write(\"y_coord\", y3d)\n",
    "        #    cv_file.write(\"z_coord\", depth)\n",
    "        #    cv_file.release()\n",
    "        #save_coefficients(x3d, y3d, depth)\n",
    "\n",
    "        #fig = plt.figure()\n",
    "        #ax = fig.add_subplot(projection='3d')\n",
    "        #ax.scatter(x3d, y3d)​\n",
    "\n",
    "        end = time.time()\n",
    "        totalTime = end - start\n",
    "    \n",
    "        # fps = 1 / totalTime\n",
    "        #print(\"FPS: \", fps)\n",
    "        \n",
    "        # cv2.putText(frame_right, f'FPS: {int(fps)}', (20,450), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0,255,0), 2)\n",
    "        # cv2.putText(frame_left, f'FPS: {int(fps)}', (20,450), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0,255,0), 2)                                   \n",
    "        \n",
    "\n",
    "        # Show the frames\n",
    "        cv2.imshow(\"frame right\", frame_right) \n",
    "        cv2.imshow(\"frame left\", frame_left)\n",
    "\n",
    "\n",
    "        # Hit \"q\" to close the window\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            # file_path = \"/Users/kgramos/Desktop/depth.csv\"\n",
    "            df.to_csv('depth.csv', index=False)\n",
    "            break\n",
    "\n",
    "# Release and destroy all windows before termination\n",
    "capr.release()\n",
    "capl.release()\n",
    "# file_path = \"/Users/kgramos/Desktop/depth.csv\"\n",
    "df.to_csv('depth.csv', index=False)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
