{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2.aruco as aruco\n",
    "import pandas as pd\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undistortRectify(frameR, frameL, leftMapX, leftMapY, rightMapX, rightMapY):\n",
    "    \"\"\"\n",
    "    Undistort and rectify frames using calibration\n",
    "    \"\"\"\n",
    "    undistortedL= cv2.remap(frameL, leftMapX, leftMapY, cv2.INTER_LANCZOS4, cv2.BORDER_CONSTANT, 0)\n",
    "    undistortedR= cv2.remap(frameR, rightMapX, rightMapY, cv2.INTER_LANCZOS4, cv2.BORDER_CONSTANT, 0)\n",
    "    return undistortedR, undistortedL\n",
    "\n",
    "def loadCoefficients():\n",
    "    \"\"\"\n",
    "    Load calibration coefficients from Calibration/calibrationCoefficients.yaml\n",
    "    - Camera calibration matrices, distortion coefficients, rotation and translation matrices\n",
    "    \"\"\"\n",
    "    dir=os.getcwd()\n",
    "    file_path = os.path.join(dir, \"../Calibration\", \"calibrationCoefficients.yaml\")\n",
    "    cv_file = cv2.FileStorage(file_path, cv2.FILE_STORAGE_READ)\n",
    "    camera_matrixL = cv_file.getNode(\"KL\").mat()\n",
    "    dist_matrixL = cv_file.getNode(\"DL\").mat()\n",
    "    camera_matrixR = cv_file.getNode(\"KR\").mat()\n",
    "    dist_matrixR = cv_file.getNode(\"DR\").mat()\n",
    "    rot = cv_file.getNode(\"rot\").mat()\n",
    "    trans = cv_file.getNode(\"trans\").mat()\n",
    "    leftMapX = cv_file.getNode(\"sLX\").mat()\n",
    "    leftMapY = cv_file.getNode(\"sLY\").mat()\n",
    "    rightMapX = cv_file.getNode(\"sRX\").mat()\n",
    "    rightMapY = cv_file.getNode(\"sRY\").mat()\n",
    "    Q = cv_file.getNode(\"Q\").mat()\n",
    "    cv_file.release()\n",
    "    return [camera_matrixL, dist_matrixL, camera_matrixR, dist_matrixR, rot, trans, leftMapX, leftMapY, rightMapX, rightMapY, Q]\n",
    "\n",
    "\n",
    "def find_depth(right_point, left_point, frame_right, frame_left, baseline, f):\n",
    "    \"\"\"\n",
    "    Compute 3D position of marker\n",
    "    \"\"\"\n",
    "    _, width_right, _ = frame_right.shape\n",
    "    height_left, width_left, _ = frame_left.shape\n",
    "    frame_left = cv2.cvtColor(frame_left, cv2.COLOR_BGR2GRAY)\n",
    "    frame_right = cv2.cvtColor(frame_right, cv2.COLOR_BGR2GRAY)\n",
    "    Ox = int(width_left/2)\n",
    "    Oy = int(height_left/2)\n",
    "\n",
    "    # Find focal length in pixels:\n",
    "    if width_right == width_left:\n",
    "         f_pixel = .14\n",
    "    else:\n",
    "         print('Left and right camera frames do not have the same pixel width')\n",
    "\n",
    "    vl = left_point[1]\n",
    "    ul = left_point[0]\n",
    "    vr = right_point[1]\n",
    "    ur = right_point[0]\n",
    "\n",
    "    # Create stereo map\n",
    "    stereoSGBM = cv2.StereoSGBM.create()\n",
    "    stereoSGBM.setMinDisparity(70) \n",
    "    stereoSGBM.setNumDisparities(32) \n",
    "    stereoSGBM.setBlockSize(13) \n",
    "    stereoSGBM.setP1(8 * 3 * stereoSGBM.getBlockSize() ** 2) \n",
    "    stereoSGBM.setP2(32 * 3 * stereoSGBM.getBlockSize() ** 2)\n",
    "    stereoSGBM.setUniquenessRatio(10) \n",
    "    stereoSGBM.setSpeckleWindowSize(50) \n",
    "    stereoSGBM.setSpeckleRange(16) \n",
    "    \n",
    "    disparitySGBM = stereoSGBM.compute(frame_left, frame_right)\n",
    "    disparity_img = disparitySGBM\n",
    "    x_disp=int(ur)\n",
    "    y_disp=int(vr)\n",
    "    disparity = disparitySGBM[x_disp,y_disp]\n",
    "    \n",
    "    # Calculate position \n",
    "    zDepth = (baseline*f_pixel)/disparity     \n",
    "    yDepth = (baseline*(vl - Oy))/disparity\n",
    "    xDepth = (baseline*(ul - Ox))/disparity\n",
    "    return xDepth, yDepth, zDepth, disparity_img, x_disp, y_disp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set video number according to Tracking/Videos (1-5)\n",
    "video_number = 1\n",
    "\n",
    "# Set color space ('RGB', 'HSL', or 'HSV')\n",
    "color_space = 'RGB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = os.getcwd()\n",
    "video_pathl = dir + \"/Videos/\" + f\"Left{video_number}.mp4\" \n",
    "video_pathr = dir + \"/Videos/\" + f\"Right{video_number}.mp4\" \n",
    "capl = cv2.VideoCapture(video_pathl)\n",
    "capr = cv2.VideoCapture(video_pathr)\n",
    "mtxL, distL, mtxR, distR, rot, trans, leftMapX, leftMapY, rightMapX, rightMapY, Q = loadCoefficients()\n",
    "\n",
    "data = {'Marker': [], 'X': [], 'Y': [], 'Z': [], 'Time': []}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "Ox = 320\n",
    "Oy = 240\n",
    "B = 12.25               # Distance between the cameras [cm]\n",
    "f = 3.67                # Camera lense's focal length [mm]\n",
    "\n",
    "while True:\n",
    "    success_right, frame_right = capr.read()\n",
    "    success_left, frame_left = capl.read()\n",
    "    # Check if either frame is None\n",
    "    if frame_right is None or frame_left is None:\n",
    "        break\n",
    "\n",
    "    # Apply rectification maps\n",
    "    frame_right = cv2.remap(frame_right, rightMapX, rightMapY, cv2.INTER_LINEAR)\n",
    "    frame_left = cv2.remap(frame_left, leftMapX, leftMapY, cv2.INTER_LINEAR)\n",
    "\n",
    "    if color_space == 'HSV':\n",
    "        # Show the frames\n",
    "        cv2.imshow(\"frame right\", frame_right) \n",
    "        cv2.imshow(\"frame left\", frame_left)\n",
    "        succes_right, frame_right = capr.read()\n",
    "        succes_left, frame_left = capl.read()\n",
    "\n",
    "        # define range of white color in HSV \n",
    "        lower_white = np.array([0,0,140])\n",
    "        upper_white = np.array([255,255,255])\n",
    "\n",
    "        hsv_right = cv2.cvtColor(frame_right, cv2.COLOR_BGR2RGB)\n",
    "        hsv_left = cv2.cvtColor(frame_left, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Threshold the HSV image to get only white colors\n",
    "        mask_right = cv2.inRange(hsv_right, lower_white, upper_white)\n",
    "        frame_right = cv2.bitwise_and(frame_right,frame_right, mask= mask_right)\n",
    "        mask_left = cv2.inRange(hsv_left, lower_white, upper_white)\n",
    "        frame_left = cv2.bitwise_and(frame_left,frame_left, mask= mask_left)\n",
    "\n",
    "        frame_right, frame_left = undistortRectify(frame_right, frame_left, leftMapX, leftMapY, rightMapX, rightMapY)\n",
    "\n",
    "        gray_r = frame_right[:,:,1]\n",
    "        gray_l = frame_left[:,:,1]\n",
    "\n",
    "        bgr_r = cv2.cvtColor(frame_right, cv2.COLOR_HSV2BGR)\n",
    "        bgr_l = cv2.cvtColor(frame_left, cv2.COLOR_HSV2BGR)\n",
    "        gray_r = cv2.cvtColor(bgr_r, cv2.COLOR_BGR2GRAY)  # Change grayscale\n",
    "        gray_l = cv2.cvtColor(bgr_l, cv2.COLOR_BGR2GRAY)  # Change grayscale\n",
    "\n",
    "    elif color_space == 'HSL':\n",
    "\n",
    "        # Show the frames\n",
    "        cv2.imshow(\"frame right\", frame_right) \n",
    "        cv2.imshow(\"frame left\", frame_left)\n",
    "        succes_right, frame_right = capr.read()\n",
    "        succes_left, frame_left = capl.read()\n",
    "\n",
    "        # define range of white color in HSV \n",
    "        lower_white = np.array([0,0,140])\n",
    "        upper_white = np.array([255,255,255])\n",
    "\n",
    "        hsv_right = cv2.cvtColor(frame_right, cv2.COLOR_BGR2RGB)\n",
    "        hsv_left = cv2.cvtColor(frame_left, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Threshold the HSV image to get only white colors\n",
    "        mask_right = cv2.inRange(hsv_right, lower_white, upper_white)\n",
    "        frame_right = cv2.bitwise_and(frame_right,frame_right, mask= mask_right)\n",
    "        mask_left = cv2.inRange(hsv_left, lower_white, upper_white)\n",
    "        frame_left = cv2.bitwise_and(frame_left,frame_left, mask= mask_left)\n",
    "\n",
    "        frame_right, frame_left = undistortRectify(frame_right, frame_left, leftMapX, leftMapY, rightMapX, rightMapY)\n",
    "\n",
    "        bgr_r = cv2.cvtColor(frame_right, cv2.COLOR_HSV2BGR)\n",
    "        bgr_l = cv2.cvtColor(frame_left, cv2.COLOR_HSV2BGR)\n",
    "        gray_r = cv2.cvtColor(bgr_r, cv2.COLOR_BGR2GRAY)  # Change grayscale\n",
    "        gray_l = cv2.cvtColor(bgr_l, cv2.COLOR_BGR2GRAY)  # Change grayscale\n",
    "       \n",
    "        pass\n",
    "\n",
    "    elif color_space == 'RGB':\n",
    "        frame_right, frame_left = undistortRectify(frame_right, frame_left, leftMapX, leftMapY, rightMapX, rightMapY)\n",
    "        gray_r = cv2.cvtColor(frame_right, cv2.COLOR_BGR2GRAY)  # Change grayscale\n",
    "        gray_l = cv2.cvtColor(frame_left, cv2.COLOR_BGR2GRAY)  # Change grayscale\n",
    "        pass\n",
    "\n",
    "    matrix_coefficients = mtxL\n",
    "    distortion_coefficients = distL\n",
    "\n",
    "    # Show the frames\n",
    "    cv2.imshow(\"frame right\", frame_right)\n",
    "    cv2.imshow(\"frame left\", frame_left)\n",
    "\n",
    "    aruco_dict = aruco.getPredefinedDictionary(aruco.DICT_4X4_100)\n",
    "    parameters = aruco.DetectorParameters_create()  # Marker detection parameters\n",
    "\n",
    "    # lists of ids and the corners beloning to each id\n",
    "    corners_r, ids_r, rejected_img_points_r = aruco.detectMarkers(gray_r, aruco_dict,\n",
    "                                                            parameters=parameters)\n",
    "    corners_l, ids_l, rejected_img_points_l = aruco.detectMarkers(gray_l, aruco_dict,\n",
    "                                                            parameters=parameters)\n",
    "\n",
    "    if not success_right or not success_left:                    \n",
    "        break\n",
    "\n",
    "    else:\n",
    "       \n",
    "        start = time.time()\n",
    "        \n",
    "        # Convert the BGR image to RGB\n",
    "        frame_right = cv2.cvtColor(frame_right, cv2.COLOR_BGR2RGB)\n",
    "        frame_left = cv2.cvtColor(frame_left, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        \n",
    "        # Convert the RGB image to BGR\n",
    "        frame_right = cv2.cvtColor(frame_right, cv2.COLOR_RGB2BGR)\n",
    "        frame_left = cv2.cvtColor(frame_left, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        Calculating Depth\n",
    "        \"\"\"\n",
    "        center_right = 0\n",
    "        center_left = 0\n",
    "  \n",
    "        if (np.all(ids_r is not None) & np.all(ids_l is not None)).any():\n",
    "        # if np.all(ids_r is not None) and np.all(ids_l is not None):  # If there are markers found by detector\n",
    "            start_time = time.time()\n",
    "            elapsed_time = time.time() - start_time\n",
    "            zipped_r = zip(ids_r, corners_r)\n",
    "            zipped_l = zip(ids_l, corners_l)\n",
    "            \n",
    "            ids_r, corners_r = zip(*(sorted(zipped_r)))\n",
    "            ids_l, corners_l = zip(*(sorted(zipped_l)))\n",
    "            \n",
    "            axis_r = np.float32([[-0.01, -0.01, 0], [-0.01, 0.01, 0], [0.01, -0.01, 0], [0.01, 0.01, 0]]).reshape(-1, 3)\n",
    "            axis_l = np.float32([[-0.01, -0.01, 0], [-0.01, 0.01, 0], [0.01, -0.01, 0], [0.01, 0.01, 0]]).reshape(-1, 3)\n",
    "\n",
    "            for i in range(0, len(ids_l)):  # Iterate in markers\n",
    "\n",
    "                if len(ids_l) != len(ids_r):\n",
    "                    continue\n",
    "                else:\n",
    "                    # Estimate pose of each marker and return the values rvec and tvec---different from camera coefficients\n",
    "                    rvec_r, tvec_r, markerPoints_r = aruco.estimatePoseSingleMarkers(corners_r[i], 0.04, matrix_coefficients, distortion_coefficients)\n",
    "                    rvec_l, tvec_l, markerPoints_l = aruco.estimatePoseSingleMarkers(corners_l[i], 0.04, matrix_coefficients, distortion_coefficients)\n",
    "            \n",
    "                    x_r = int(np.mean(corners_r[i][0][:,0]))\n",
    "                    x_l = int(np.mean(corners_l[i][0][:,0]))\n",
    "                    y_r = int(np.mean(corners_r[i][0][:,1]))\n",
    "                    y_l = int(np.mean(corners_l[i][0][:,1]))\n",
    "\n",
    "                    center_point_right = np.array([x_r, y_r])\n",
    "                    center_point_left = np.array([x_l, y_l])\n",
    "                    aruco.drawDetectedMarkers(frame_right, corners_r)  # Draw a square around the markers\n",
    "                    aruco.drawDetectedMarkers(frame_left, corners_l)  # Draw a square around the markers\n",
    "        \n",
    "                    # If no marker can be caught in one camera show text \"TRACKING LOST\"\n",
    "                    if not np.all(ids_r is not None) or not np.all(ids_l is not None):\n",
    "                        cv2.putText(frame_right, \"TRACKING LOST\", (75,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255),2)\n",
    "                        cv2.putText(frame_left, \"TRACKING LOST\", (75,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255),2)\n",
    "\n",
    "                    else:\n",
    "                        # Function to calculate depth of object. Outputs vector of all depths in case of several balls.\n",
    "                        x3d, y3d, depth, disparity_img, x_disp, y_disp = find_depth(center_point_right, center_point_left, frame_right, frame_left, B, f)\n",
    "                        disparity_img = cv2.normalize(disparity_img, None, 0, 1.0, cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "                        cv2.imshow(\"disp\",disparity_img)\n",
    "                        disp_img = cv2.circle(disparity_img, (x_disp, y_disp), 20, (255, 0, 0), 10)\n",
    "                        cv2.imshow(\"disp\",disp_img)\n",
    "                        cv2.putText(frame_left, \"3D: (\" + str(round(x3d,3)) + ', ' + str(round(y3d,3)) + ', ' + str(round(depth,3)) + ')', (50,50), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0,255,0),3)\n",
    "\n",
    "                        df2 = pd.DataFrame([[ids_r[i][0], x3d, y3d, depth, elapsed_time]], columns=['Marker', 'X', 'Y', 'Z','Time'])\n",
    "                        df = pd.concat([df, df2])\n",
    "                        \n",
    "        end = time.time()\n",
    "        totalTime = end - start\n",
    "\n",
    "        # Show the frames\n",
    "        cv2.imshow(\"frame right\", frame_right) \n",
    "        cv2.imshow(\"frame left\", frame_left)\n",
    "\n",
    "\n",
    "        # Hit \"q\" to close the window\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            df.to_csv('positions.csv', index=False)\n",
    "            break\n",
    "\n",
    "# Release and destroy all windows before termination\n",
    "capr.release()\n",
    "capl.release()\n",
    "df.to_csv('positions.csv', index=False)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
